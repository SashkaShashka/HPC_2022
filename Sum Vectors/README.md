# Привет <img src="https://github.com/blackcater/blackcater/raw/main/images/Hi.gif" height="32"/> </br>
# Сложение векторов
## Содержимое репозитория и описание 
### Содержимое 
* В файле .h содержится код хоста и функция для последовательного сложения 2х векторов</br>
* В файле .cu содержится функция ядра</h5>
* Make файл используется для компоновки и представляетс собой файл с флагами</br>
* После компоновки, используя команду make код запускается с помощью команды ./Add n BLOCK_SIZE GRID_SIZE count_iteration (длина векторов, кол-во нитей, кол-во блоков, count_iteration - для усреднения резульатов в тестах)</br>
* В xlsx содержится таблица и графики результатов</br>
### Что распараллеливалось
Не знаю зачем этот пункт, но, по заданию нужно написать, что именно распараллеливалось. А именно сумма, где каждая нить делала сложение векторов А и В, где в случае когда кол-во нитей меньше, чем размер вектора, то каждой нити достается несколько операций, индекс который вычисляется как i+count_treads.</br>
### Описание файлов
#### .h 
1. Выделяется память для 4 массивов: A,B,CGPU,CCPU и рандомно заполняются массивы А и В</br>
2. Выделяется память на GPU и копируются туда массивы</br>
3. Происходит запуск ядра</br>
4. Вычисление на GPU</br>
5. Копирования обратно на CPU</br>
6. Замер времени распараллеленного алгоритма</br>
7. Запуск последовательного алгоритма</br>
8. Замек времени </br>
9. Вычисление ускорения</br>
10. Вычисление ошибки</br>
11. Очищение памяти</br>
12. Алгоритм выполняет count_iteration раз</br>
13. Считается усредненное время</br>
#### .cu 
1. Используется виртуальная архитектура CUDAдля вычисления количества выделенных нитей и индекса для каждой нити</br>
2. Каждая нить вычисляет i-ый элемент вектора С, как сумму A и B, если же нитей меньше, чем размер вектора, то каждой нити достается несколько операций, индекс который вычисляется как i+count_treads.</br>
## Эксперимент
### Постановка эксперимента</br>
Очень жаль, но мне не удалось найти нормальную библиотеку для работы с векторами (которая была понятна, не требовала разбора, но была хоть как-то оптимизирована для сложения векторов большой длины), поэтому эксперименты проводились только на с++ и CUDA. Делать последовательный алгоритм на С#, я не видел никакого смысла.
### Пару слов о потерянном времени и моем эксперименте с параллелилизмом на С#
Я убил около 6 часов, чтобы как-то написать, оптимизировать свою версию распаралленного алгоритма с помощью Task-ов (задачи, которые могут выполняться параллельно) на С#. Получились алгоритмы, очень похожие на на алгоритм ядра. Но я, честно говоря не понял, почему не было абсолютно никакого плюса в производительности... Сделал очень много тестов с разным кол-вом тасков, но получил лишь одно - с увеличением кол-ва тасков расло и время выполнения программы, стабильно, но не линейно. По всей видимости создание таска, ожидание завершения какого-либо b назначение нового занимает ОЧЕНЬ МНОГО времени. Хотя первый алгоритм, который представлен ниже показал почти прямую... Но сравнивать с кудой я отказался. Пара скринов: </br>
![image](https://user-images.githubusercontent.com/62326372/194729679-97bbcfce-993f-4d57-8bff-53e3693b0994.png) </br>
![image](https://user-images.githubusercontent.com/62326372/194729688-c82a56b6-fd15-4dcb-ac1b-13aae3ec5bfc.png) </br>
### Эксперимент 
Был проведен эксперинт, где сначала фиксировался размер вектора равный 1_084_576 и менялось кол-во блоков от 1 до 1024, а кол-во нитей в блоке. </br></br>
Имеем следующие результаты: </br>
![image](https://user-images.githubusercontent.com/62326372/194729807-da12bc35-df22-488d-b59a-653992e45f40.png) </br>
![image](https://user-images.githubusercontent.com/62326372/194729821-557b500e-7a6d-468c-a133-90b6fe330b48.png) </br>
Далее зафиксируем кол-во нитей, равное 1024 и будем увеличивать размер массивов от 1024, до 1_084_576 с шагом х2. </br>
Получим следующие результаты: </br>
![image](https://user-images.githubusercontent.com/62326372/194729872-d875d016-126f-4ee2-8e44-4287b58d7172.png) </br>
![image](https://user-images.githubusercontent.com/62326372/194729876-8eabc7af-f26c-495f-b6d1-2f385799d6a9.png) </br>
### Итоговые выводы
Безусловно использовать куду для нахождения суммы массивов при больших размерах целесообразно. При маленьких нет, т.к. время на создание нитей больше, чем время затраченное на суммирование. Разумеется, что можно вычислить время на создание варпа (очень примерно или найти в интернете, если эта инфа есть). Решить задачу оптимизации для нахождения лучшего кол-ва блоков и нитей и получить лучшее ускорение. Насколько это реальная задача не знаю.
